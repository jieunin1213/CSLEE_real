{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler,MaxAbsScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "column_names = ['breed','color','weigt','age','adoption']\n",
    "dataset = pd.read_csv('dog_info_final(3).csv',names=column_names)\n",
    "\n",
    "#scaler 적용\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = RobustScaler()\n",
    "scaler3 = MinMaxScaler()\n",
    "scaler4 = MaxAbsScaler()\n",
    "\n",
    "dataset[['breed','color','weigt','age']] = scaler1.fit_transform(dataset[['breed','color','weigt','age']])\n",
    "#sns.pairplot(dataset, hue='adoption')\n",
    "#plt.show()\n",
    "\n",
    "#seed값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "    ##y값의 활성화 함수 적용\n",
    "data = dataset.values\n",
    "X=data[:,0:4].astype(float)\n",
    "Y_obj = data[:,4]\n",
    "\n",
    "########################################################################################################################\n",
    "#SVR모델\n",
    "'''\n",
    "#학습셋과 테스트셋의 구분\n",
    "X_train, X_valtest, Y_train, Y_valtest = train_test_split(X,Y_obj,test_size=0.2,random_state=seed)\n",
    "print(Y_valtest.shape)\n",
    "\n",
    "# Fitting SVR to the dataset\n",
    "from sklearn.svm import SVR\n",
    "polysvr = SVR(kernel=\"poly\", degree=2, gamma=1, coef0=0).fit(X, Y_obj)\n",
    "rbfsvr = SVR(kernel=\"rbf\").fit(X, Y_obj)\n",
    "sigmoidsvr = SVR(kernel=\"sigmoid\", gamma=2, coef0=2).fit(X, Y_obj)\n",
    "\n",
    "Y_valtest_pred = rbfsvr.predict(X_valtest)\n",
    "mse = mean_squared_error(Y_valtest,Y_valtest_pred)\n",
    "evs = explained_variance_score(Y_valtest,Y_valtest_pred)\n",
    "r2 = rbfsvr.score(X_valtest,Y_valtest)\n",
    "print(\"\\n###Performance ####\")\n",
    "print(\"Mean squared error =\",round(mse,2))\n",
    "print(\"Explained variance score =\",round(evs,2))\n",
    "print(\"r2squre =\",round(r2,2))\n",
    "'''\n",
    "########################################################################################################################\n",
    "#머신러닝 시도\n",
    "\n",
    "## Y차원 늘린후 0 or 1로 만들기 : one-hot-encoding\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "Y_encoded = np_utils.to_categorical(Y)\n",
    "\n",
    "#학습셋과 테스트셋의 구분\n",
    "X_train, X_valtest, Y_train, Y_valtest = train_test_split(X,Y_encoded,test_size=0.2,random_state=seed)\n",
    "print(Y_valtest.shape)\n",
    "\n",
    "#classification모델\n",
    "## make model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=4, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, input_dim=4, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history =model.fit(X_train, Y_train, validation_data=(X_valtest,Y_valtest), epochs=10, batch_size=5)\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_valtest,Y_valtest)[1]))\n",
    "\n",
    "model.save(\"model_jj.h5\",\"w\")\n",
    "\n",
    "y_vloss=history.history['val_loss']\n",
    "y_loss =history.history['loss']\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len,y_vloss,\"^\",c=\"red\",markersize=4,label=\"Validation_loss\")\n",
    "plt.plot(x_len,y_loss,\"o\",c=\"blue\",markersize=4,label=\"Train_loss\")\n",
    "plt.plot(x_len,y_acc,\"D\",c=\"black\",markersize=4,label=\"Train_accuracy\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss / accuracy')\n",
    "plt.show()\n",
    "\n",
    "test_data = dataset.sample(2)\n",
    "test_data=test_data.values\n",
    "x_test = test_data[:,0:4]\n",
    "y_test = test_data[:,4]\n",
    "\n",
    "print(model.summary())\n",
    "#predict 는 probability를 predict_class 는 label 을 제공한다.\n",
    "pred_result1=model.predict(x_test)                 #regression결과값\n",
    "pred_result2=model.predict_classes(x_test)         #classification결과값\n",
    "\n",
    "print(pred_result1)\n",
    "print(pred_result2)\n",
    "########################################################################################################################\n",
    "\n",
    "'''회기 모델\n",
    "# define base model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(2, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -0.19 (0.01) MSE\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler,MaxAbsScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "column_names = ['breed','color','weigt','age','adoption']\n",
    "dataset = pd.read_csv('(0814)dog_info_final(6).csv',names=column_names)\n",
    "\n",
    "#scaler 적용\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = RobustScaler()\n",
    "scaler3 = MinMaxScaler()\n",
    "scaler4 = MaxAbsScaler()\n",
    "\n",
    "dataset[['breed','color','weigt','age']] = scaler1.fit_transform(dataset[['breed','color','weigt','age']])\n",
    "#sns.pairplot(dataset, hue='adoption')\n",
    "#plt.show()\n",
    "\n",
    "#seed값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "    ##y값의 활성화 함수 적용\n",
    "data = dataset.values\n",
    "X=data[:,0:4].astype(float)\n",
    "Y_obj = data[:,4]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "Y_encoded = np_utils.to_categorical(Y)\n",
    "\n",
    "X_train, X_valtest, Y_train, Y_valtest = train_test_split(X,Y_encoded,test_size=0.2,random_state=seed)\n",
    "\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(2, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
